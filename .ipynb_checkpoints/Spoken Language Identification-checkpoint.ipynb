{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (0.10.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from soundfile) (1.11.5)\n",
      "Requirement already satisfied: pycparser in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from cffi>=1.0->soundfile) (2.18)\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Requirement already satisfied: scikit-learn in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from sklearn) (0.20.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.15.1)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/fahmisalman/Library/Caches/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorflow in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (1.9.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: tensorboard<1.10.0,>=1.9.0 in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from tensorflow) (1.9.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from tensorflow) (0.31.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from tensorflow) (1.15.1)\n",
      "Requirement already satisfied: setuptools<=39.1.0 in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from tensorflow) (39.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow) (0.14.1)\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile\n",
    "!pip install sklearn\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import scipy.signal as signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>languange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.00274658203125, 0.004486083984375, 0.010803...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.07891845703125, 0.09246826171875, 0.1100769...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.007354736328125, -0.007415771484375, -0.00...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.038848876953125, 0.04473876953125, 0.055511...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.000335693359375, -0.000244140625, 0.0032043...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              series languange\n",
       "0  [0.00274658203125, 0.004486083984375, 0.010803...        de\n",
       "1  [0.07891845703125, 0.09246826171875, 0.1100769...        de\n",
       "2  [-0.007354736328125, -0.007415771484375, -0.00...        de\n",
       "3  [0.038848876953125, 0.04473876953125, 0.055511...        de\n",
       "4  [0.000335693359375, -0.000244140625, 0.0032043...        de"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = 'dataset/train/'\n",
    "\n",
    "series = []\n",
    "length = []\n",
    "for filename in os.listdir(train_path):\n",
    "    flac, samplerate = sf.read(train_path+filename)\n",
    "    series.append(flac)\n",
    "    length.append(samplerate)\n",
    "    \n",
    "label = []\n",
    "for filename in os.listdir(train_path):\n",
    "    label.append(filename[:2])\n",
    "    \n",
    "data = {'series': series,\n",
    "       'languange':label}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>languange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0025634765625, 0.002227783203125, 0.0018005...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.00830078125, 0.01513671875, -0.02392578125...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[6.103515625e-05, 0.0, 0.0, 6.103515625e-05, 0...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0067138671875, 0.000152587890625, 0.0022888...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.03125, 0.0198974609375, 0.015869140625, 0.0...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              series languange\n",
       "0  [0.0025634765625, 0.002227783203125, 0.0018005...        de\n",
       "1  [-0.00830078125, 0.01513671875, -0.02392578125...        de\n",
       "2  [6.103515625e-05, 0.0, 0.0, 6.103515625e-05, 0...        de\n",
       "3  [0.0067138671875, 0.000152587890625, 0.0022888...        de\n",
       "4  [0.03125, 0.0198974609375, 0.015869140625, 0.0...        de"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = 'dataset/test/'\n",
    "\n",
    "series = []\n",
    "length = []\n",
    "for filename in os.listdir(test_path):\n",
    "    flac, samplerate = sf.read(test_path+filename)\n",
    "    series.append(flac)\n",
    "    length.append(samplerate)\n",
    "    \n",
    "label = []\n",
    "for filename in os.listdir(test_path):\n",
    "    label.append(filename[:2])\n",
    "    \n",
    "data_test = {'series': series,\n",
    "       'languange':label}\n",
    "\n",
    "df_test = pd.DataFrame(data_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import librosa\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    return label_binarizer.transform(x)\n",
    "\n",
    "x = np.array(df['series'])\n",
    "x_t = np.array(df_test['series'])\n",
    "y_train = df['languange']\n",
    "y_test = df_test['languange']\n",
    "\n",
    "# Convert Pandas DataFrame into Numpy array\n",
    "x_train = np.zeros((len(x), 431))\n",
    "for i in range(len(x_train)):\n",
    "    a = librosa.feature.zero_crossing_rate(x[i])\n",
    "    x_train[i] = a\n",
    "    \n",
    "x_test = np.zeros((len(x_t), 431))\n",
    "for i in range(len(x_test)):\n",
    "    a = librosa.feature.zero_crossing_rate(x_t[i])\n",
    "    x_test[i] = a\n",
    "    \n",
    "# Convert label into one hot encoding\n",
    "label_binarizer = LabelBinarizer()\n",
    "label_binarizer.fit(y_train) # need to be global or remembered to use it later\n",
    "y_train_onehot = one_hot_encode(y_train)\n",
    "\n",
    "label_binarizer.fit(y_test) # need to be global or remembered to use it later\n",
    "y_test_onehot = one_hot_encode(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de' 'de' 'de' 'de' 'de' 'de' 'en' 'de' 'de' 'en' 'en' 'de' 'de' 'de'\n",
      " 'de' 'de' 'de' 'de' 'en' 'en' 'en' 'de' 'de' 'en' 'de' 'de' 'de' 'en'\n",
      " 'de' 'de' 'de' 'de' 'de' 'de' 'de' 'de' 'en' 'en' 'en' 'de' 'en' 'en'\n",
      " 'en' 'en' 'en' 'de' 'en' 'en' 'en' 'en' 'en' 'en' 'en' 'en' 'de' 'en'\n",
      " 'de' 'de' 'es' 'de' 'de' 'de' 'de' 'de' 'en' 'de' 'en' 'de' 'de' 'de'\n",
      " 'de' 'de' 'es' 'es' 'es' 'es' 'es' 'es' 'es' 'es' 'es' 'es' 'es' 'es'\n",
      " 'es' 'es' 'es' 'es' 'es' 'es' 'es' 'es' 'es' 'es' 'de' 'es' 'es' 'de'\n",
      " 'es' 'es' 'es' 'es' 'es' 'de' 'es' 'de' 'de' 'es']\n",
      "Train: 0.8148148148148148\n",
      "Test : 0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "print(clf.predict(x_test))\n",
    "print('Train:', clf.score(x_train, y_train))\n",
    "print('Test :', clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.0\n",
      "Test : 0.6481481481481481\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(10), random_state=1)\n",
    "\n",
    "clf.fit(x_train, y_train_onehot)\n",
    "print('Train:', clf.score(x_train, y_train_onehot))\n",
    "print('Test :', clf.score(x_test, y_test_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-93a75cfce9b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Anaconda3.6/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    868\u001b[0m         \"\"\"\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Anaconda3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    745\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/.conda/envs/Anaconda3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 565\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             _assert_all_finite(array,\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(x_train, y_train)\n",
    "print('Train:', clf.score(x_train, y_train))\n",
    "print('Test :', clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fahmisalman/.conda/envs/Anaconda3.6/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.6782407407407407\n",
      "Test : 0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(x_train, y_train)\n",
    "print('Train:', clf.score(x_train, y_train))\n",
    "print('Test :', clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_5 (GRU)                  (None, 256)               198144    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 198,915\n",
      "Trainable params: 198,915\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1\n",
      "432/432 [==============================] - 15s 35ms/step - loss: 0.2208 - acc: 0.3866\n",
      "[0.21808820576579482, 0.37037037037037035]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential, models\n",
    "from tensorflow.keras.layers import LSTM, Dense, Flatten, GRU\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "\n",
    "def train(x, y, epoch=20, hidden=256):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=hidden, input_shape=(x.shape[1], 1)))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    model.fit(x, y, epochs=epoch, batch_size=64, verbose=1)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(x, y, model):\n",
    "    mse = model.evaluate(x, y, verbose=0)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def save_model(model, s):\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model/%s.json\" % s, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"model/%s.h5\" % s)\n",
    "\n",
    "\n",
    "def load_model(s):\n",
    "    model_json = open('model/%s.json' % s, 'r').read()\n",
    "    model = models.model_from_json(model_json)\n",
    "    model.load_weights(\"model/%s.h5\" % s)\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(x, model):\n",
    "    return model.predict(x)\n",
    "\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "model = train(x_train, y_train_onehot, epoch=1)\n",
    "print(evaluate(x_test, y_test_onehot, model))\n",
    "save_model(model, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
